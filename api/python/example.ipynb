{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from dawg import PyDawg\n",
    "\n",
    "dawg_path = \"/net/nfs.cirrascale/allennlp/davidw/proj/proj-rusty-dawg/rusty-dawg/dawg/wikitext-2-raw.dawg\"\n",
    "\n",
    "# Make sure the tokenizer matches the one used to construct the DAWG.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "py_dawg = PyDawg(dawg_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': [1722, 351, 2180, 569, 18354, 8704, 17740, 1830, 837, 569, 18354, 7496, 17740, 6711], 'suffix_contexts': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 'context_counts': [234, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Substring found in the Wikitext 2 train data.\n",
    "query = \"As with previous Valkyira Chronicles games , Valkyria Chronicles III\"\n",
    "\n",
    "# Get suffix contexts\n",
    "suffix_contexts = py_dawg.get_suffix_context(query)\n",
    "\n",
    "print(suffix_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': (1722,), 'count': 234, 'text': 'As'}\n",
      "{'tokens': (1722, 351), 'count': 9, 'text': 'As with'}\n",
      "{'tokens': (1722, 351, 2180), 'count': 1, 'text': 'As with previous'}\n",
      "{'tokens': (1722, 351, 2180, 569), 'count': 1, 'text': 'As with previous V'}\n",
      "{'tokens': (1722, 351, 2180, 569, 18354), 'count': 1, 'text': 'As with previous Valky'}\n",
      "{'tokens': (1722, 351, 2180, 569, 18354, 8704), 'count': 1, 'text': 'As with previous Valkyira'}\n",
      "{'tokens': (1722, 351, 2180, 569, 18354, 8704, 17740), 'count': 1, 'text': 'As with previous Valkyira Chronicles'}\n",
      "{'tokens': (1722, 351, 2180, 569, 18354, 8704, 17740, 1830), 'count': 1, 'text': 'As with previous Valkyira Chronicles games'}\n",
      "{'tokens': (1722, 351, 2180, 569, 18354, 8704, 17740, 1830, 837), 'count': 1, 'text': 'As with previous Valkyira Chronicles games,'}\n",
      "{'tokens': (1722, 351, 2180, 569, 18354, 8704, 17740, 1830, 837, 569), 'count': 1, 'text': 'As with previous Valkyira Chronicles games, V'}\n",
      "{'tokens': (1722, 351, 2180, 569, 18354, 8704, 17740, 1830, 837, 569, 18354), 'count': 1, 'text': 'As with previous Valkyira Chronicles games, Valky'}\n",
      "{'tokens': (1722, 351, 2180, 569, 18354, 8704, 17740, 1830, 837, 569, 18354, 7496), 'count': 1, 'text': 'As with previous Valkyira Chronicles games, Valkyria'}\n",
      "{'tokens': (1722, 351, 2180, 569, 18354, 8704, 17740, 1830, 837, 569, 18354, 7496, 17740), 'count': 1, 'text': 'As with previous Valkyira Chronicles games, Valkyria Chronicles'}\n",
      "{'tokens': (1722, 351, 2180, 569, 18354, 8704, 17740, 1830, 837, 569, 18354, 7496, 17740, 6711), 'count': 1, 'text': 'As with previous Valkyira Chronicles games, Valkyria Chronicles III'}\n"
     ]
    }
   ],
   "source": [
    "# Return a list of all substrings in the DAWG that match the query.\n",
    "matching_substrings = py_dawg.get_matching_substrings(query)\n",
    "\n",
    "for entry in matching_substrings:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts are weird. There are ~15K occurrences of \"as\" in the train corpus.\n",
    "If I call `dawg.get_count()` before transitioning, I get way too many occurrences (like 2M). If I call it after, I get too few (like 200). How do I get the counts?\n",
    "\n",
    "Also, we have redundant substrings. For instance, \"As with previous\" only occurs as a substring of \"As with previous V\". I think that if `s` is a substring of `t`, we should keep `s` if its count is greater than `t`, and otherwise throw it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': (5842,), 'count': 4, 'text': 'Us'}\n",
      "{'tokens': (391,), 'count': 271, 'text': 'ain'}\n",
      "{'tokens': (18100,), 'count': 4, 'text': ' bolt'}\n",
      "{'tokens': (900,), 'count': 725, 'text': ' set'}\n",
      "{'tokens': (900, 262), 'count': 29, 'text': ' set the'}\n",
      "{'tokens': (262, 995), 'count': 347, 'text': ' the world'}\n",
      "{'tokens': (262, 995, 1700), 'count': 2, 'text': ' the world record'}\n",
      "{'tokens': (995, 1700, 287), 'count': 1, 'text': ' world record in'}\n",
      "{'tokens': (995, 1700, 287, 262), 'count': 1, 'text': ' world record in the'}\n",
      "{'tokens': (995, 1700, 287, 262, 1802), 'count': 1, 'text': ' world record in the 100'}\n",
      "{'tokens': (12,), 'count': 17027, 'text': '-'}\n",
      "{'tokens': (14470,), 'count': 7, 'text': ' dash'}\n",
      "{'tokens': (13,), 'count': 8668, 'text': '.'}\n"
     ]
    }
   ],
   "source": [
    "query = \"Usain bolt set the world record in the 100-meter dash.\"\n",
    "suffix_context = py_dawg.get_suffix_context(query)\n",
    "matching_substrings = py_dawg.get_matching_substrings(query)\n",
    "\n",
    "for substring in matching_substrings:\n",
    "    print(substring)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently the token \"meter\" never appears?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': (21943,), 'count': 2347039, 'text': 'foo'}\n",
      "{'tokens': (21943, 22944), 'count': 2347039, 'text': 'foo foo'}\n",
      "{'tokens': (21943, 22944, 22944), 'count': 2347039, 'text': 'foo foo foo'}\n",
      "{'tokens': (21943, 22944, 22944, 22944), 'count': 2347039, 'text': 'foo foo foo foo'}\n"
     ]
    }
   ],
   "source": [
    "query = \"foo foo foo foo\"\n",
    "matching_substrings = py_dawg.get_matching_substrings(query)\n",
    "for entry in matching_substrings:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [21943, 22944, 22944, 22944],\n",
       " 'suffix_contexts': [0, 0, 0, 0],\n",
       " 'context_counts': [2347039, 2347039, 2347039, 2347039]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_dawg.get_suffix_context(\"foo foo foo foo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird bug here; what happened? Does the \"-\" character do something funky?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': (21943,), 'count': 2347039, 'text': 'foo'}\n",
      "{'tokens': (12,), 'count': 17027, 'text': '-'}\n",
      "{'tokens': (5657,), 'count': 126, 'text': 'bar'}\n"
     ]
    }
   ],
   "source": [
    "query = \"foo-bar\"\n",
    "matching_substrings = py_dawg.get_matching_substrings(query)\n",
    "\n",
    "for substring in matching_substrings:\n",
    "    print(substring)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rusty-dawg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
